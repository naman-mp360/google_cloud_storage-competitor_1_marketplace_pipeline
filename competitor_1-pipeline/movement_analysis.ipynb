{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834d86c4",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9ca8cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import gspread\n",
    "gc = gspread.oauth()\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import gzip\n",
    "import glob\n",
    "\n",
    "import haversine as hs\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57cd52",
   "metadata": {},
   "source": [
    "### instantiating the google cloud object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d834d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the google cloud storage client using the credentials\n",
    "storage_client = storage.Client.from_service_account_json('ds_credentials_edit.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633f28bd",
   "metadata": {},
   "source": [
    "### creating a bucket on google cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7871384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring the bucket name to be created\n",
    "# bucket_name = 'ds_competitor_1_marketplace_scraped_data'\n",
    "\n",
    "# # create a new bucket\n",
    "# new_bucket = storage_client.bucket(bucket_name)\n",
    "# new_bucket.storage_class = 'STANDARD'\n",
    "\n",
    "# # returns Bucket object\n",
    "# created_bucket = storage_client.create_bucket(new_bucket, location='asia-south1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a1f3d",
   "metadata": {},
   "source": [
    "### calling the google cloud storage bucket object and pushing not yet uploaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3614d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the bucket name from which the date needs to be fetched\n",
    "bucket_name = 'ds_competitor_1_marketplace_scraped_data'\n",
    "\n",
    "# get the bucket object from the storage_client\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af86b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring empty list to store the filenames that needs to be downloaded from the bucket\n",
    "blob_file_names = []\n",
    "\n",
    "# get names of all the blobs in the bucket\n",
    "for blob_ in bucket.list_blobs():\n",
    "    blob_file_names.append(blob_.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8431e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawling through folder to get all the file names with local directory\n",
    "local_path = \"/home/customer/Narada/ScrapedData\"\n",
    "all_folders = glob.glob(local_path + '/**')\n",
    "files_uploaded_dir_remote = []\n",
    "files_uploaded_dir_local = []\n",
    "\n",
    "while len(all_folders)!=0:\n",
    "    local_file = all_folders.pop()\n",
    "    if not os.path.isfile(local_file):\n",
    "        all_folders.extend(glob.glob(local_file + '/**'))\n",
    "    else:\n",
    "        files_uploaded_dir_remote.append(local_file[22:])\n",
    "        files_uploaded_dir_local.append(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6da91c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for the directory path and file_names\n",
    "all_file_dir = pd.DataFrame({'remote':files_uploaded_dir_remote,\\\n",
    "                         'local':files_uploaded_dir_local\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0857c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the files that need to pushed to google cloud storage\n",
    "file_dir = all_file_dir[~all_file_dir['remote'].isin(blob_file_names)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10f314e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of file to be uploaded to google cloud storage\n",
    "len(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c54235b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterating and trying to upload all data programatically\n",
    "for i in tqdm(range(len(file_dir))):\n",
    "    # Name of the object to be stored in the bucket\n",
    "    object_name_in_bucket = bucket.blob(file_dir['remote'].iloc[i])\n",
    "    \n",
    "    # Name of the object in local file system\n",
    "    object_name_in_bucket.upload_from_filename(file_dir['local'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81821a4",
   "metadata": {},
   "source": [
    "### segregating and labelling the files into \"Animal Details\", \"Seller Details\" and \"Resource Details\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dfabb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segragating \"Animal Details\", \"Resources\" and \"Seller Info\" files\n",
    "def labelling_files(x):\n",
    "    # handling bad files\n",
    "    if len(x.split(\".\")[0])>5:\n",
    "        # splitting \"file name\" into 'sub_file_name_tokens'\n",
    "        sub_file_name_tokens = x.split(\".\")[0].split(\"_\")\n",
    "\n",
    "        # getting 'file_type' - AD/seller/resource\n",
    "        file_type = sub_file_name_tokens[-1]\n",
    "\n",
    "        # getting 'date_scraped'\n",
    "        date_scraped = sub_file_name_tokens[-2]\n",
    "\n",
    "        # getting 'state' (cross checking)\n",
    "        state = sub_file_name_tokens[0]\n",
    "        \n",
    "        # returns data as tuple\n",
    "        return [file_type, date_scraped, state]\n",
    "\n",
    "    else:\n",
    "        return ['NA', 'NA', 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d65d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting file_names to segregate and process files\n",
    "file_names = [item.split(\"/\")[-1] for item in files_uploaded_dir_local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ffc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame with details of all the files in our 'ScrapedData' for 'classified' business\n",
    "file_df = pd.DataFrame({'file_names':file_names,\\\n",
    "                        'location':files_uploaded_dir_local\n",
    "                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "793086d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding metaData to the 'file_df' DataFrame\n",
    "file_df[['file_type','date_scraped','state']] = file_df['file_names'].apply(lambda x:labelling_files(x)).tolist()\n",
    "\n",
    "# dropping 'NA' rows\n",
    "file_df = file_df[file_df['state']!='NA']\n",
    "\n",
    "# converting 'date_scraped' to datetime format, and sorting dataFrame\n",
    "file_df['date_scraped'] = pd.to_datetime(file_df['date_scraped'])\n",
    "file_df.sort_values(by='date_scraped', inplace=True)\n",
    "file_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "836a5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching most recent sample \"classified-animal_details\" excel file\n",
    "AD_files = file_df[file_df['file_type']=='AD'].reset_index(drop=True)\n",
    "\n",
    "# fetching most recent sample \"classified-seller\" excel file\n",
    "seller_files = file_df[file_df['file_type']=='seller'].reset_index(drop=True)\n",
    "\n",
    "# fetching most recent sample \"classified-resource\" excel file\n",
    "resource_files = file_df[file_df['file_type']=='resource'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3f017",
   "metadata": {},
   "source": [
    "### all ANIMAL details files cattle movement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58a2592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate all \"Animal Details\" excel files\n",
    "def get_animal_details(files_df_):\n",
    "    # declaring empty list to concat all dataFrames\n",
    "    dflist = []\n",
    "    \n",
    "    # looping and concatenating\n",
    "    for i in range(len(files_df_)):#[-10] to take most recent 10 days scraped data\n",
    "        \n",
    "        # file_path of all excel files\n",
    "        file_path_ = files_df_['location'].iloc[i]\n",
    "\n",
    "        # reading the file        \n",
    "        df1 = pd.read_excel(file_path_)\n",
    "        df1['date_scraped'] = files_df_['date_scraped'].iloc[i]\n",
    "        df1['date_scraped'] = pd.to_datetime(df1['date_scraped'])\n",
    "        df1['listing_state'] = files_df_['state'].iloc[i]\n",
    "        df1['file_age'] = df1['date_scraped'].apply(lambda x: int((datetime.today() - x).days)+1)\n",
    "        dflist.append(df1)\n",
    "        \n",
    "    # concatenating and dropping index\n",
    "    concatenated_df = pd.concat(dflist).reset_index().drop('index',axis=1)\n",
    "    \n",
    "    # renaming columns\n",
    "    concatenated_df.rename(columns={'_id':'cattle_id','userId':'seller_id', 'seller':'seller_name', 'state':'listing_status'}, inplace=True)\n",
    "    \n",
    "    # returning the concatenated dataFrame\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e51e9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the dataFrames concatenating function\n",
    "all_animal_details_df = get_animal_details(AD_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e289851a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropping off \"PENDING\" and \"STA\" listing_status - only 2 such instances\n",
    "all_ad_df = all_animal_details_df[all_animal_details_df['listing_status']=='ACTIVE'].copy()\n",
    "\n",
    "# getting all unique 'cattle_id'\n",
    "all_ad_df['cattle_id'] = all_ad_df['cattle_id'].astype(str)\n",
    "\n",
    "# converting columns into 'datetime' format\n",
    "all_ad_df['publishedOn'] = pd.to_datetime(all_ad_df['publishedOn'])\n",
    "all_ad_df['date_scraped'] = pd.to_datetime(all_ad_df['date_scraped'])\n",
    "\n",
    "# getting the 'last_scraped_date'\n",
    "last_scraped_date = all_ad_df['date_scraped'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "579fc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN values\n",
    "all_ad_df['description'].fillna(\"-\", inplace=True)\n",
    "all_ad_df['deliveredBefore'].fillna(-999, inplace=True)\n",
    "all_ad_df['hasDelivered'].fillna(-999, inplace=True)\n",
    "all_ad_df['isPregnant'].fillna(-999, inplace=True)\n",
    "all_ad_df['pregnancyMonth'].fillna(-999, inplace=True)\n",
    "all_ad_df['calf'].fillna('-', inplace=True)\n",
    "all_ad_df['partnerId'].fillna(-999, inplace=True)\n",
    "all_ad_df['hasContacted'].fillna(-999, inplace=True)\n",
    "all_ad_df['breed'].fillna(\"-\", inplace=True)\n",
    "\n",
    "# replacing int 0 value with str\n",
    "all_ad_df['calf'].replace(0,'-', inplace=True)\n",
    "all_ad_df['breed'].replace(0,'-', inplace=True)\n",
    "\n",
    "# dropping redundant columns\n",
    "all_ad_df.drop(columns=['description'], inplace=True)\n",
    "all_ad_df.drop(columns=['district'], inplace=True)\n",
    "all_ad_df.drop(columns=['dynamicLink'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67cbefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped based on \"cattle_id\", sorted by \"date_scraped\", taking the last occurence\n",
    "cattle_sold = pd.DataFrame(all_ad_df.sort_values(by='date_scraped').groupby('cattle_id').tail(1)).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba7b08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get listing_status(Sold/Unsold/Fresh_listing) an the no. of days taken to sell item if sold\n",
    "def get_listing_status(x, last_scraped_dt):\n",
    "    # \"UnSold\" listing\n",
    "    if ((last_scraped_dt-pd.to_datetime(x['date_scraped'])).days)==0:\n",
    "        days_to_sell = -999\n",
    "        sold_status = 'UNSOLD'\n",
    "    # \"Fresh\" listing\n",
    "    elif ((last_scraped_dt-pd.to_datetime(x['publishedOn']).tz_localize(None).replace(hour=0, minute=0, second=0, microsecond=0)).days)==0:\n",
    "        days_to_sell = -999\n",
    "        sold_status = 'FRESH_LISTING'\n",
    "    # \"De-listed\" listing\n",
    "    elif int((pd.to_datetime(x['date_scraped'])-pd.to_datetime(x['publishedOn']).tz_localize(None).replace(hour=0, minute=0, second=0, microsecond=0)).days)+1==29:\n",
    "        days_to_sell = -999\n",
    "        sold_status = 'DELISTED_LISTING'\n",
    "    # \"Sold\" listing\n",
    "    else:\n",
    "        days_to_sell = int((pd.to_datetime(x['date_scraped'])-pd.to_datetime(x['publishedOn']).tz_localize(None).replace(hour=0, minute=0, second=0, microsecond=0)).days)+1\n",
    "        sold_status = 'Yes'\n",
    "     \n",
    "    # returning the no. of \"days_taken_to_sell\" and the final \"sold_status\"\n",
    "    return [days_to_sell, sold_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e0d03bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the \"get_listing_status\" function\n",
    "cattle_sold[['days_to_sell', 'sold_status']] = cattle_sold.apply(lambda y:get_listing_status(y, last_scraped_date),axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e00305c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 37)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b862cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding date of results to cattle_sold csv file_name\n",
    "cattle_sold_file_name = \"processed_data_files/cattle_sold_df_\"+str(datetime.today().date())+\".parquet\"\n",
    "\n",
    "# saving to disk\n",
    "cattle_sold.to_parquet(cattle_sold_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a244475",
   "metadata": {},
   "source": [
    "### all SELLER details files contact number mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a2976ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to concatenate all \"Seller\" excel files\n",
    "def get_seller_details(files_df_):\n",
    "    # declaring empty list to concat all dataFrames\n",
    "    dflist = []\n",
    "    \n",
    "    # looping and concatenating\n",
    "    for i in range(len(files_df_)):#[-10] to take most recent 10 days scraped data\n",
    "        \n",
    "        # file_path of all excel files\n",
    "        file_path_ = files_df_['location'].iloc[i]\n",
    "        \n",
    "        # reading the file\n",
    "        df1 = pd.read_excel(file_path_)\n",
    "        df1['date_scraped'] = files_df_['date_scraped'].iloc[i]\n",
    "        df1['date_scraped'] = pd.to_datetime(df1['date_scraped'])\n",
    "        df1['listing_state'] = files_df_['state'].iloc[i]\n",
    "        df1['file_age'] = df1['date_scraped'].apply(lambda x: int((datetime.today() - x).days)+1)\n",
    "        dflist.append(df1)\n",
    "        \n",
    "    # concatenating and dropping index\n",
    "    concatenated_df = pd.concat(dflist).reset_index().drop('index',axis=1)\n",
    "    \n",
    "    # renaming columns\n",
    "    concatenated_df.rename(columns={'_id':'cattle_id','userId':'seller_id', 'seller':'seller_name', 'state':'listing_status'}, inplace=True)\n",
    "    \n",
    "    # returning the concatenated dataFrame\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30c6b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the dataFrames concatenating function\n",
    "all_seller_details_df = get_seller_details(seller_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b635efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging and filtering out 10 digit seller_id\n",
    "all_seller_details_df['contact_number_y/n'] = all_seller_details_df['id'].apply(lambda x: \"Yes\" \\\n",
    "                                                                                if(len(str(x))==10) else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2739d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contacts = all_seller_details_df[all_seller_details_df['contact_number_y/n'] == 'Yes'].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8c7f84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts_cattle_id = all_contacts[['cattle_id','id']].copy()\n",
    "contacts_cattle_id.rename(columns={'id':'contact_number'}, inplace=True)\n",
    "contacts_cattle_id['contact_number'] = contacts_cattle_id['contact_number'].astype(int)\n",
    "contacts_cattle_id.drop_duplicates(inplace=True)\n",
    "contacts_cattle_id.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c04d0a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22696, 2)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts_cattle_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f4d2aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding date of results to all_animal_details csv file_name\n",
    "contacts_cattle_id_file_name = \"processed_data_files/all_seller_details_df_\"+str(datetime.today().date())+\".parquet\"\n",
    "\n",
    "# saving to disk\n",
    "contacts_cattle_id.to_parquet(contacts_cattle_id_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb7010",
   "metadata": {},
   "source": [
    "### all cattles pincode mapping - gmap_lat_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ef2f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the current gmap_lat_long_mapping csv\n",
    "gmap_lat_long_mapping_df = pd.read_csv(\"gmap_mapping_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "094bfb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1yybUEyelVjqX4AfwRqgRJ4EK19CakSNVaFHkCqzZ8PA',\n",
       " 'updatedRange': 'current!A1:K91873',\n",
       " 'updatedRows': 91873,\n",
       " 'updatedColumns': 11,\n",
       " 'updatedCells': 1010603}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Written to \"classified_AD_movement_analysis\"\n",
    "worksheet = gc.open_by_key('1yybUEyelVjqX4AfwRqgRJ4EK19CakSNVaFHkCqzZ8PA').worksheet('current')\n",
    "# raw_data\n",
    "lat_long_data = [gmap_lat_long_mapping_df.columns.astype(str).tolist()]+gmap_lat_long_mapping_df.values.astype(str).tolist()\n",
    "# writing the sheet\n",
    "worksheet.update('A1', lat_long_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a94b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out 'cattle_ids' that need to be mapped\n",
    "tbd_df = cattle_sold[~cattle_sold['cattle_id'].isin(gmap_lat_long_mapping_df['cattle_id'].tolist())].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a51e688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3418, 37)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a71d4a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1yybUEyelVjqX4AfwRqgRJ4EK19CakSNVaFHkCqzZ8PA',\n",
       " 'updatedRange': 'tbd_cattles!A1:AK3419',\n",
       " 'updatedRows': 3419,\n",
       " 'updatedColumns': 37,\n",
       " 'updatedCells': 126503}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Written to \"classified_AD_movement_analysis\"\n",
    "worksheet = gc.open_by_key('1yybUEyelVjqX4AfwRqgRJ4EK19CakSNVaFHkCqzZ8PA').worksheet('tbd_cattles')\n",
    "# raw_data\n",
    "tbd_cattles_data = [tbd_df.columns.astype(str).tolist()]+tbd_df.values.astype(str).tolist()\n",
    "# writing the sheet\n",
    "worksheet.update('A1', tbd_cattles_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d2f60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the GMAP lat_long data\n",
    "lat_long_df = pd.read_csv(\"GMAP_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440233da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in tqdm(tbd_df.iterrows()):\n",
    "    lat = float(row['lat'])\n",
    "    long = float(row['long'])\n",
    "    source = (lat,long)\n",
    "    distance_matrixs = {}\n",
    "    for j, row_ in lat_long_df.iterrows():\n",
    "        glat = float(row_['Lat_GMAP'])\n",
    "        glong = float(row_['Long_GMAP'])\n",
    "        destination = (glat,glong)\n",
    "        distance = hs.haversine(source,destination)\n",
    "        distance_matrixs[j] = distance\n",
    "\n",
    "    distance_matrixs = sorted(distance_matrixs.items(), key=lambda x:x[1])\n",
    "    distance_mats = dict(distance_matrixs)\n",
    "    max_idx = list(distance_mats.keys())[0]\n",
    "\n",
    "    tbd_df.loc[i,'idx'] = max_idx\n",
    "    tbd_df.loc[i,'GLong'] = lat_long_df.iloc[max_idx]['Long_GMAP']\n",
    "    tbd_df.loc[i,'GLat'] = lat_long_df.iloc[max_idx]['Lat_GMAP']\n",
    "    tbd_df.loc[i,'Pincode'] = lat_long_df.iloc[max_idx]['Pincode']\n",
    "    tbd_df.loc[i,'Distance'] = distance_mats[max_idx]*1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "784077db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be retained from tbd_df\n",
    "col_names = gmap_lat_long_mapping_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated \"gmap_mapping_result\" dataframe\n",
    "gmap_mapping_result = pd.concat([gmap_lat_long_mapping_df,tbd_df[col_names]],axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee9c1846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91872, 11)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmap_lat_long_mapping_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13151ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding date of results to all_animal_details csv file_name\n",
    "gmap_lat_long_file_name = \"processed_data_files/gmap_lat_long_mapping_df_\"+str(datetime.today().date())+\".parquet\"\n",
    "\n",
    "# saving to disk\n",
    "gmap_lat_long_mapping_df.to_parquet(gmap_lat_long_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a3c1ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to disk\n",
    "gmap_lat_long_mapping_df.to_csv(\"gmap_mapping_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f30bb66",
   "metadata": {},
   "source": [
    "### indian postal code pincode.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7600ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv\n",
    "pincode_df = pd.read_csv(\"pincode.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6155b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157126, 11)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pincode_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ac529da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincodes_df = pincode_df[['Pincode','District','StateName']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f0e4b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincodes_df = pincodes_df.rename(columns={'Pincode':'gmap_pincode',\\\n",
    "                            'District':'gmap_district',\\\n",
    "                            'StateName':'gmap_state',\\\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "303ccc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincodes_df = pincodes_df.drop_duplicates(subset=['gmap_pincode']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "09b1de82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19300, 3)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pincodes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1940a",
   "metadata": {},
   "source": [
    "### adding features for reports/analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b55343",
   "metadata": {},
   "source": [
    "#### contacts mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "13e0b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 37)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "932cbbd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22696, 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contacts_cattle_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e45f6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold = cattle_sold.merge(contacts_cattle_id, left_on='cattle_id', right_on='cattle_id', how='left').fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0f09e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold['contact_number'] = cattle_sold['contact_number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d4be15cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 38)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0f799",
   "metadata": {},
   "source": [
    "#### gmap lat long mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6e07d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap_lat_long_df = gmap_lat_long_mapping_df[['cattle_id','GLong','GLat','Pincode']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "54d5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap_lat_long_df = gmap_lat_long_df.rename(columns={'Pincode':'gmap_pincode',\\\n",
    "                                 'GLong':'gmap_long',\\\n",
    "                                 'GLat':'gmap_lat',\\\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a639ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold = cattle_sold.merge(gmap_lat_long_df, left_on='cattle_id', right_on='cattle_id', how='left').fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c64c056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold['gmap_pincode'] = cattle_sold['gmap_pincode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8616e8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 41)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7750b88",
   "metadata": {},
   "source": [
    "#### pincode state and district mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "05fe950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 41)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fdbe297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold = cattle_sold.merge(pincodes_df, left_on='gmap_pincode', right_on='gmap_pincode', how='left').fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d226f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold = cattle_sold.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5b86f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 43)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be679d6",
   "metadata": {},
   "source": [
    "#### adding week names and date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "79ce8b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 43)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "720e7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cattle_sold['month_of_sale'] = cattle_sold['date_scraped'].dt.month_name()\n",
    "cattle_sold['week_of_sale'] = (cattle_sold['date_scraped']+pd.DateOffset(1)).dt.isocalendar().week\n",
    "cattle_sold['year_of_sale'] = cattle_sold['date_scraped'].dt.year\n",
    "cattle_sold['weekday'] = cattle_sold['date_scraped'].dt.strftime('%A')\n",
    "cattle_sold['week_start_date'] = cattle_sold['date_scraped'].apply(lambda x: (x-timedelta(days=(x.weekday()+1)%7)).strftime('%d %b'))\n",
    "cattle_sold['week_end_date'] = cattle_sold['date_scraped'].apply(lambda x: (x-timedelta(days=(x.weekday()+1)%7) + timedelta(days=6)).strftime('%d %b'))\n",
    "cattle_sold['sale_week'] = cattle_sold.apply(lambda x: str(x['week_start_date']) + \" - \" + str(x['week_end_date']), axis=1)\n",
    "cattle_sold['sale_day'] = cattle_sold['date_scraped'].apply(lambda x: str(x.strftime('%d %b')) + \": \" + str(x.strftime('%a')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "81afa250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95290, 51)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cattle_sold.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e259bf5",
   "metadata": {},
   "source": [
    "#### renaming and standardizing the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e85b2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy of the dataframe\n",
    "data = cattle_sold.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "79c08560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing column names for google cloud storage\n",
    "col_names_mapping = {'viewCount':'view_count_animall',\\\n",
    "                     'callCount':'call_count_animall',\\\n",
    "                     '_score':'score',\\\n",
    "                     'long':'listing_long',\\\n",
    "                     'lat':'listing_lat',\\\n",
    "                     'highestMilk':'highest_milk',\\\n",
    "                     'locationName':'location_name',\\\n",
    "                     'isNegotiable':'is_negotiable',\\\n",
    "                     'publishedOn':'published_on',\\\n",
    "                     'currentMilk':'current_milk',\\\n",
    "                     'deliveredBefore':'delivered_before',\\\n",
    "                     'hasDelivered':'has_delivered',\\\n",
    "                     'isPregnant':'is_pregnant',\\\n",
    "                     'pregnancyMonth':'pregnancy_month',\\\n",
    "                     'age':'cattle_age',\\\n",
    "                     'animalType':'animal_type',\\\n",
    "                     'partnerId':'partner_id',\\\n",
    "                     'hasContacted':'has_contacted',\\\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d15f7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "data = data.rename(columns=col_names_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc80f1",
   "metadata": {},
   "source": [
    "#### standardizing the column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a1434a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distance'] = data['distance'].astype(float)\n",
    "data['rating'] = data['rating'].astype(float)\n",
    "data['view_count_animall'] = data['view_count_animall'].astype(int)\n",
    "data['call_count_animall'] = data['call_count_animall'].astype(int)\n",
    "data['recency'] = data['recency'].astype(int)\n",
    "data['score'] = data['score'].astype(float)\n",
    "data['listing_long'] = data['listing_long'].astype(float)\n",
    "data['listing_lat'] = data['listing_lat'].astype(float)\n",
    "data['highest_milk'] = data['highest_milk'].astype(float)\n",
    "data['is_negotiable'] = data['is_negotiable'].astype(int)\n",
    "data['published_on'] = pd.to_datetime(data['published_on'])\n",
    "data['current_milk'] = data['current_milk'].astype(float)\n",
    "data['delivered_before'] = data['delivered_before'].apply(lambda x: float(x) if x!='-' else x)\n",
    "data['has_delivered'] = data['has_delivered'].apply(lambda x: float(x) if x!='-' else x)\n",
    "data['is_pregnant'] = data['is_pregnant'].apply(lambda x: float(x) if x!='-' else x)\n",
    "data['pregnancy_month'] = data['pregnancy_month'].apply(lambda x: float(x) if x!='-' else x)\n",
    "data['price'] = data['price'].astype(float)\n",
    "data['cattle_age'] = data['cattle_age'].astype(float)\n",
    "data['lactation'] = data['lactation'].astype(int)\n",
    "data['date_scraped'] = pd.to_datetime(data['date_scraped'])\n",
    "data['file_age'] = data['file_age'].astype(int)\n",
    "data['days_to_sell'] = data['days_to_sell'].apply(lambda x: int(x) if len(str(x))<=2 else x)\n",
    "data['week_of_sale'] = data['week_of_sale'].apply(lambda x: int(x) if x!='UNSOLD' else x)\n",
    "data['year_of_sale'] = data['year_of_sale'].apply(lambda x: int(x) if x!='UNSOLD' else x)\n",
    "data['gmap_pincode'] = data['gmap_pincode'].apply(lambda x: int(x) if x!='-' else x)\n",
    "data['contact_number'] = data['contact_number'].apply(lambda x: int(x) if x not in ['NA','-'] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709cce49",
   "metadata": {},
   "source": [
    "### converting to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "60c0c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('furnished_data/cattle_sold_data.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58589d0",
   "metadata": {},
   "source": [
    "### creating a bucket on google cloud storage for final furnished data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e2c55d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring the bucket name to be created\n",
    "# bucket_name = 'ds_competitor_1_marketplace_reporting'\n",
    "\n",
    "# # create a new bucket\n",
    "# new_bucket = storage_client.bucket(bucket_name)\n",
    "# new_bucket.storage_class = 'STANDARD'\n",
    "\n",
    "# # returns Bucket object\n",
    "# created_bucket = storage_client.create_bucket(new_bucket, location='asia-south1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b2dac6",
   "metadata": {},
   "source": [
    "### pushing to google cloud storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "78a382ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the bucket name from which the date needs to be fetched\n",
    "bucket_name = 'ds_competitor_1_marketplace_reporting'\n",
    "\n",
    "# get the bucket object from the storage_client\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e81c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the object to be stored in the bucket\n",
    "object_name_in_bucket = bucket.blob('movement_analysis.parquet')\n",
    "\n",
    "# local folder name\n",
    "local_folder = os.getcwd()\n",
    "\n",
    "# local file location\n",
    "filename = \"%s/%s\" % (local_folder, 'furnished_data/cattle_sold_data.parquet')\n",
    "\n",
    "# Name of the object in local file system\n",
    "object_name_in_bucket.upload_from_filename(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf956d",
   "metadata": {},
   "source": [
    "### reading parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d3dbc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_analysis_df = pd.read_parquet('furnished_data/cattle_sold_data.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3a707023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cattle_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>rating</th>\n",
       "      <th>view_count_animall</th>\n",
       "      <th>call_count_animall</th>\n",
       "      <th>recency</th>\n",
       "      <th>score</th>\n",
       "      <th>listing_long</th>\n",
       "      <th>listing_lat</th>\n",
       "      <th>gender</th>\n",
       "      <th>listing_status</th>\n",
       "      <th>highest_milk</th>\n",
       "      <th>seller_name</th>\n",
       "      <th>location_name</th>\n",
       "      <th>is_negotiable</th>\n",
       "      <th>published_on</th>\n",
       "      <th>current_milk</th>\n",
       "      <th>delivered_before</th>\n",
       "      <th>has_delivered</th>\n",
       "      <th>is_pregnant</th>\n",
       "      <th>pregnancy_month</th>\n",
       "      <th>price</th>\n",
       "      <th>cattle_age</th>\n",
       "      <th>animal_type</th>\n",
       "      <th>breed</th>\n",
       "      <th>calf</th>\n",
       "      <th>lactation</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>has_contacted</th>\n",
       "      <th>type</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>listing_state</th>\n",
       "      <th>file_age</th>\n",
       "      <th>days_to_sell</th>\n",
       "      <th>sold_status</th>\n",
       "      <th>contact_number</th>\n",
       "      <th>gmap_long</th>\n",
       "      <th>gmap_lat</th>\n",
       "      <th>gmap_pincode</th>\n",
       "      <th>gmap_district</th>\n",
       "      <th>gmap_state</th>\n",
       "      <th>month_of_sale</th>\n",
       "      <th>week_of_sale</th>\n",
       "      <th>year_of_sale</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week_start_date</th>\n",
       "      <th>week_end_date</th>\n",
       "      <th>sale_week</th>\n",
       "      <th>sale_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62db79e6d17eaf000bd8235c</td>\n",
       "      <td>15504404057</td>\n",
       "      <td>22593.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>94.020466</td>\n",
       "      <td>77.4294</td>\n",
       "      <td>28.6380</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rajendra Singh</td>\n",
       "      <td>Shanti Nagar, Nai Basti Dundahera, Ghaziabad, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-24 11:00:41.809000+00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COW</td>\n",
       "      <td>AMERICAN CROSS</td>\n",
       "      <td>MALE</td>\n",
       "      <td>2</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-999</td>\n",
       "      <td>77.4349</td>\n",
       "      <td>28.6302</td>\n",
       "      <td>201016</td>\n",
       "      <td>GHAZIABAD</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24 Jul</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>24 Jul - 30 Jul</td>\n",
       "      <td>25 Jul: Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62dc1cfa136fa3000b12e148</td>\n",
       "      <td>9971568876</td>\n",
       "      <td>6734.546414</td>\n",
       "      <td>4.0</td>\n",
       "      <td>204</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>94.302968</td>\n",
       "      <td>77.3570</td>\n",
       "      <td>28.6908</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>15.0</td>\n",
       "      <td>aasim</td>\n",
       "      <td>ग़ाज़ियाबाद, ग़ाज़ियाबाद ज़िला, उत्तर प्रदेश 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-24 01:50:32.946000+00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BUFFALO</td>\n",
       "      <td>MURRAH CROSS</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9971568876</td>\n",
       "      <td>77.3748</td>\n",
       "      <td>28.6806</td>\n",
       "      <td>201007</td>\n",
       "      <td>GHAZIABAD</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24 Jul</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>24 Jul - 30 Jul</td>\n",
       "      <td>25 Jul: Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62d90613cc5dfe000b998567</td>\n",
       "      <td>15503320123</td>\n",
       "      <td>13008.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>193</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>94.434781</td>\n",
       "      <td>77.4128</td>\n",
       "      <td>28.7451</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Kasama</td>\n",
       "      <td>Ghaziabad, Ghaziabad District, Uttar Pradesh, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-21 07:56:39.855000+00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>COW</td>\n",
       "      <td>JERSEY CROSS</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>2</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-999</td>\n",
       "      <td>77.4128</td>\n",
       "      <td>28.7451</td>\n",
       "      <td>201003</td>\n",
       "      <td>GHAZIABAD</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24 Jul</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>24 Jul - 30 Jul</td>\n",
       "      <td>25 Jul: Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62dd1d9086feac000aea6332</td>\n",
       "      <td>15506020485</td>\n",
       "      <td>14064.189741</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>93.601063</td>\n",
       "      <td>77.3133</td>\n",
       "      <td>28.6504</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>krishansharma</td>\n",
       "      <td>Anand Vihar, Vivek Vihar Tehsil, Shahdara, Del...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-24 13:07:01.312000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>COW</td>\n",
       "      <td>DESI CROSS</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-999</td>\n",
       "      <td>77.3027</td>\n",
       "      <td>28.6502</td>\n",
       "      <td>110092</td>\n",
       "      <td>EAST</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24 Jul</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>24 Jul - 30 Jul</td>\n",
       "      <td>25 Jul: Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62dd29eb07b924000aeb4502</td>\n",
       "      <td>15505988041</td>\n",
       "      <td>26287.119752</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.551751</td>\n",
       "      <td>77.4460</td>\n",
       "      <td>28.5185</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Navneet</td>\n",
       "      <td>ग्रेटर नोएडा, Gautam Buddha Nagar, Gautam Budd...</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-25 03:52:28.101000+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BUFFALO</td>\n",
       "      <td>MURRAH CROSS</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>DELHI</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-999</td>\n",
       "      <td>77.4521</td>\n",
       "      <td>28.5239</td>\n",
       "      <td>201306</td>\n",
       "      <td>GAUTAM BUDDHA NAGAR</td>\n",
       "      <td>UTTAR PRADESH</td>\n",
       "      <td>July</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>Monday</td>\n",
       "      <td>24 Jul</td>\n",
       "      <td>30 Jul</td>\n",
       "      <td>24 Jul - 30 Jul</td>\n",
       "      <td>25 Jul: Mon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cattle_id    seller_id      distance  rating  \\\n",
       "0  62db79e6d17eaf000bd8235c  15504404057  22593.000000     3.0   \n",
       "1  62dc1cfa136fa3000b12e148   9971568876   6734.546414     4.0   \n",
       "2  62d90613cc5dfe000b998567  15503320123  13008.000000     4.0   \n",
       "3  62dd1d9086feac000aea6332  15506020485  14064.189741     3.0   \n",
       "4  62dd29eb07b924000aeb4502  15505988041  26287.119752     3.0   \n",
       "\n",
       "   view_count_animall  call_count_animall  recency      score  listing_long  \\\n",
       "0                  74                   3        0  94.020466       77.4294   \n",
       "1                 204                  28        1  94.302968       77.3570   \n",
       "2                 193                  35        3  94.434781       77.4128   \n",
       "3                  83                   2        0  93.601063       77.3133   \n",
       "4                  16                   0        0  94.551751       77.4460   \n",
       "\n",
       "   listing_lat  gender listing_status  highest_milk     seller_name  \\\n",
       "0      28.6380  FEMALE         ACTIVE          14.0  Rajendra Singh   \n",
       "1      28.6908  FEMALE         ACTIVE          15.0           aasim   \n",
       "2      28.7451  FEMALE         ACTIVE          15.0          Kasama   \n",
       "3      28.6504  FEMALE         ACTIVE          11.0   krishansharma   \n",
       "4      28.5185  FEMALE         ACTIVE          14.0         Navneet   \n",
       "\n",
       "                                       location_name  is_negotiable  \\\n",
       "0  Shanti Nagar, Nai Basti Dundahera, Ghaziabad, ...              1   \n",
       "1  ग़ाज़ियाबाद, ग़ाज़ियाबाद ज़िला, उत्तर प्रदेश 2...              1   \n",
       "2  Ghaziabad, Ghaziabad District, Uttar Pradesh, ...              1   \n",
       "3  Anand Vihar, Vivek Vihar Tehsil, Shahdara, Del...              1   \n",
       "4  ग्रेटर नोएडा, Gautam Buddha Nagar, Gautam Budd...              1   \n",
       "\n",
       "                      published_on  current_milk  delivered_before  \\\n",
       "0 2022-07-24 11:00:41.809000+00:00          10.0              0.00   \n",
       "1 2022-07-24 01:50:32.946000+00:00          12.0              0.25   \n",
       "2 2022-07-21 07:56:39.855000+00:00           8.0              4.00   \n",
       "3 2022-07-24 13:07:01.312000+00:00           0.0           -999.00   \n",
       "4 2022-07-25 03:52:28.101000+00:00           0.0           -999.00   \n",
       "\n",
       "   has_delivered  is_pregnant  pregnancy_month    price  cattle_age  \\\n",
       "0            1.0          0.0           -999.0  38000.0         5.0   \n",
       "1            1.0          0.0           -999.0  86000.0         0.0   \n",
       "2            1.0          1.0              1.0  15000.0         0.0   \n",
       "3            0.0          1.0              2.0  11500.0         2.0   \n",
       "4            0.0          1.0              9.0  92000.0         5.0   \n",
       "\n",
       "  animal_type           breed    calf  lactation  partner_id  has_contacted  \\\n",
       "0         COW  AMERICAN CROSS    MALE          2      -999.0         -999.0   \n",
       "1     BUFFALO    MURRAH CROSS       -          2      -999.0         -999.0   \n",
       "2         COW    JERSEY CROSS  FEMALE          2      -999.0         -999.0   \n",
       "3         COW      DESI CROSS       -          2      -999.0         -999.0   \n",
       "4     BUFFALO    MURRAH CROSS       -          2      -999.0         -999.0   \n",
       "\n",
       "   type  coordinates date_scraped listing_state  file_age  days_to_sell  \\\n",
       "0     0            0   2022-07-25         DELHI        60             2   \n",
       "1     0            0   2022-07-25         DELHI        60             2   \n",
       "2     0            0   2022-07-25         DELHI        60             5   \n",
       "3     0            0   2022-07-25         DELHI        60             2   \n",
       "4     0            0   2022-07-25         DELHI        60             1   \n",
       "\n",
       "  sold_status  contact_number  gmap_long  gmap_lat  gmap_pincode  \\\n",
       "0         Yes            -999    77.4349   28.6302        201016   \n",
       "1         Yes      9971568876    77.3748   28.6806        201007   \n",
       "2         Yes            -999    77.4128   28.7451        201003   \n",
       "3         Yes            -999    77.3027   28.6502        110092   \n",
       "4         Yes            -999    77.4521   28.5239        201306   \n",
       "\n",
       "         gmap_district     gmap_state month_of_sale  week_of_sale  \\\n",
       "0            GHAZIABAD  UTTAR PRADESH          July            30   \n",
       "1            GHAZIABAD  UTTAR PRADESH          July            30   \n",
       "2            GHAZIABAD  UTTAR PRADESH          July            30   \n",
       "3                 EAST          DELHI          July            30   \n",
       "4  GAUTAM BUDDHA NAGAR  UTTAR PRADESH          July            30   \n",
       "\n",
       "   year_of_sale weekday week_start_date week_end_date        sale_week  \\\n",
       "0          2022  Monday          24 Jul        30 Jul  24 Jul - 30 Jul   \n",
       "1          2022  Monday          24 Jul        30 Jul  24 Jul - 30 Jul   \n",
       "2          2022  Monday          24 Jul        30 Jul  24 Jul - 30 Jul   \n",
       "3          2022  Monday          24 Jul        30 Jul  24 Jul - 30 Jul   \n",
       "4          2022  Monday          24 Jul        30 Jul  24 Jul - 30 Jul   \n",
       "\n",
       "      sale_day  \n",
       "0  25 Jul: Mon  \n",
       "1  25 Jul: Mon  \n",
       "2  25 Jul: Mon  \n",
       "3  25 Jul: Mon  \n",
       "4  25 Jul: Mon  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movement_analysis_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
